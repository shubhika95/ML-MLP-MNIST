{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6331ZSsQGY3"
   },
   "source": [
    "# COMP 551 - Mini-project 3\n",
    "Group 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ifel1K0gBWt_"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "%matplotlib inline                                 \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.debugger import set_trace  \n",
    "import scipy.sparse as sparse\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b08Mmbs8lr81"
   },
   "source": [
    "## Task 1. Data pre-processing\n",
    "\n",
    "- Load the raw data from Keras.\n",
    "- Vectorize 28*28 pictures to 1D vector.\n",
    "- Normalize the intensity of the pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZyGXlaKojgz"
   },
   "source": [
    "Load the MNIST dataset distributed with Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N01fKjwJDKAz",
    "outputId": "71f5a15e-c570-4d2b-b58d-1a419626e5d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28) (60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rX8l1wVDOiN"
   },
   "source": [
    "Vectorize the 28*28 pictures to a 784 vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4gvmJN6DPxI",
    "outputId": "5b6530c7-3c93-46db-b1ae-a26053cc1c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (-1, 784)).astype('float32')\n",
    "x_test = np.reshape(x_test, (-1, 784)).astype('float32')\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQqnKrdkEcw6"
   },
   "source": [
    "The intensity ranges from 0 to 255. We divide all intensities by the maximum (255) to obtain a [0-1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-s4iFV3Ez3H",
    "outputId": "8d9bd003-d98f-4735-ef44-009bb77c63c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intensity before normalization: 0.0 255.0\n",
      "Intensity after normalization: 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Intensity before normalization:', np.amin(x_train), np.amax(x_train))\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "print('Intensity after normalization:', np.amin(x_train), np.amax(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUnquDPg1D-k"
   },
   "source": [
    "We transform the (N,) vector of labels using one-hot encoding into a (N,C) matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9fXA7QipDn4Z"
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9j0ZFP-81zIY",
    "outputId": "d8bf6ea5-d4b1-4e48-c0f6-61f621161e12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10) (10000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)\n",
    "print(y_train[0:3,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-m3fZmPK14rd"
   },
   "source": [
    "Subset the data to use in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fx0N2a_Q1hMO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"data_slice = 3000\\nx_train = x_train[:data_slice,:]\\ny_train = y_train[:data_slice,:]\\nx_test = x_test[:data_slice,:]\\ny_test = y_test[:data_slice,:]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"data_slice = 3000\n",
    "x_train = x_train[:data_slice,:]\n",
    "y_train = y_train[:data_slice,:]\n",
    "x_test = x_test[:data_slice,:]\n",
    "y_test = y_test[:data_slice,:]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpKU5kZOJkEe"
   },
   "source": [
    "## Task 2. Multilayer perceptron implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6FNYQoRs0ue"
   },
   "source": [
    "### 2.1 Build the network\n",
    "Our task is a multiclass classification.The cost function will be the multi-class cross-entropy loss. We will use the following architecture:\n",
    "- output layer = softmax activation\n",
    "- hidden layers (0, 1 or 2): 128 units, ReLu, tanh or logistic activation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUW6HFnH43cv"
   },
   "source": [
    "First, we implement the activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "L1skqPZ_s0uq"
   },
   "outputs": [],
   "source": [
    "# logistic/sigmoid\n",
    "logistic = lambda z: 1./ (1 + np.exp(-z))\n",
    "\n",
    "# softmax\n",
    "eps=1e-8\n",
    "def softmax(z):\n",
    "    logits = z - np.max(z) # for numerical stability\n",
    "    sum_logits = np.sum(np.exp(logits), axis=1) +eps\n",
    "    softmax = np.exp(logits)/sum_logits[:,None] \n",
    "    return softmax\n",
    "\n",
    "#defining the tanh activation function\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh2deriv(output):\n",
    "    return 1 - (output ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxFKbS58_69S"
   },
   "source": [
    "Next, we build the MLP class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oKIoaax3f6f0"
   },
   "outputs": [],
   "source": [
    "# for 2 hidden layer with tanh activation function\n",
    "class MLP2layer_tanh:\n",
    "    \n",
    "    def __init__(self, M = 128):\n",
    "        self.M = M\n",
    "            \n",
    "    def fit(self, x_train, y_train, x_test, y_test, optimizer):\n",
    "        N = x_train.shape[0]\n",
    "        C = y_train.shape[1] # number of classes\n",
    "        D = x_train.shape[1]\n",
    "        def gradient(x, y, params):\n",
    "            v, w, u = params\n",
    "            # forward pass\n",
    "            n = x.shape[0]\n",
    "            # add bias to the input layer\n",
    "            x = np.column_stack([x,np.ones(n)*0.1])\n",
    "            b = np.ones((n,1))*0.1\n",
    "\n",
    "            q1 = np.dot(x, v) #np.column_stack([np.dot(x, v),np.ones(N)*0.1]) #trying adding bias here\n",
    "            z1 = tanh(np.hstack((q1,b))) #N x M want to column stack to add bias here\n",
    "            q2 = np.dot(z1,w) #np.column_stack([np.dot(z1,w),np.ones(N)*0.1]) #trying adding bias here\n",
    "            z2 = tanh(np.hstack((q2,b)))\n",
    "            yh = softmax(np.dot(z2, u))#N x C\n",
    "            # backward pass => gradient formula adapted from class dw = (yh-y)*z, dv = (yh-y)*w*tanh2deriv(q)*x\n",
    "            \n",
    "            dy = yh - y #N x C\n",
    "            \n",
    "            du = np.dot(z2.T,dy)/N\n",
    "            \n",
    "            #print(dz2.shape)  \n",
    "            dz2 = np.dot(dy,u.T)\n",
    "            dz2 = np.delete(dz2, -1, axis=1)\n",
    "            dq2 = tanh2deriv(q2)\n",
    "            #print(dz2.T * dq2)\n",
    "            dw = np.dot(z1.T, dz2 * dq2)/N #M x C\n",
    "            dz1 = np.dot(dz2, w.T) #N x M\n",
    "            dz1 = np.delete(dz1,-1,axis=1)\n",
    "            dq1 = tanh2deriv(q1)\n",
    "            dv = np.dot(x.T, dz1 * dq1)/N #D x M\n",
    "            dparams = [dv, dw, du]\n",
    "            return dparams\n",
    "        \n",
    "        # initialize the parameters with values in the standard normal distribution and scaled to be low\n",
    "        u = np.random.randn(self.M+1,C) * 0.1 #M x C\n",
    "        w = np.random.randn(self.M+1,self.M) * .01 #M x M\n",
    "        v = np.random.randn(D+1,self.M) * .01 #D x M\n",
    "        \n",
    "        params0 = [v,w,u]\n",
    "\n",
    "        # run the mini-batch gradient descent to update the parameters\n",
    "        self.params, self.train_loss, self.test_loss = optimizer.run(gradient, x_train, y_train, x_test, y_test, params0)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x):\n",
    "        v, w, u = self.params\n",
    "        # add bias to the input layer\n",
    "        Nt = x.shape[0]\n",
    "        x = np.column_stack([x,np.ones(Nt)*0.1])\n",
    "        b1 = np.ones((Nt,1))*0.1\n",
    "     \n",
    "        # forward pass only using updated parameters\n",
    "\n",
    "        q1 = np.dot(x,v)\n",
    "        z1 = tanh(np.hstack((q1,b1)))\n",
    "        q2 = np.dot(z1,w)\n",
    "        z2 = tanh(np.hstack((q2,b1)))\n",
    "        yh = softmax(np.dot(z2, u))#N x C\n",
    "        return yh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65sh_GyGNkqO"
   },
   "source": [
    "### 2.2 Implement the cost and accuracy function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IgiPvgSbNuZG"
   },
   "outputs": [],
   "source": [
    "# Softmax cross entropy \n",
    "def logsumexp(Z):                                                # dimension N x C\n",
    "    Zmax = np.max(Z,axis=1)[:,None]                              # max over C\n",
    "    log_sum_exp = Zmax + np.log(np.sum(np.exp(Z - Zmax), axis=1))\n",
    "    return log_sum_exp\n",
    "\n",
    "# cost for tanh activation - two layers\n",
    "def cost_tanh(x, y, params):\n",
    "  Nt = x.shape[0]\n",
    "  v, w, u = params\n",
    "  b1 = np.ones((Nt,1))*0.1\n",
    "  xb = np.column_stack([x,np.ones(Nt)*0.1])\n",
    "  q1 = np.dot(xb, v) \n",
    "  z1 = tanh(np.hstack((q1,b1))) \n",
    "  q2 = np.dot(z1,w)\n",
    "  z2 = tanh(np.hstack((q2,b1)))\n",
    "  q3 = np.dot(z2, u) #N x C\n",
    "  nll = - np.mean(np.sum(q3*y, 1) - logsumexp(q3)) \n",
    "  return nll\n",
    "\n",
    "# Accuracy\n",
    "def evaluate_acc(y, yh):\n",
    "  y_pred = np.argmax(yh,axis=1)\n",
    "  accuracy = np.count_nonzero(y_pred == np.argmax(y,axis=1))/y.shape[0]\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzCYnVR2OZ7c"
   },
   "source": [
    "### 2.3 Implement the optimizer\n",
    "\n",
    "We will use a mini-batch gradient-descent algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1u1OikUgk3hk"
   },
   "outputs": [],
   "source": [
    "def create_mini_batch(x, y, batch_size): \n",
    "    D = x.shape[1]\n",
    "    data = np.hstack((x, y))\n",
    "    np.random.shuffle(data)\n",
    "    mini = data[:batch_size,:]                                                    \n",
    "    x_mini = mini[:,:D]\n",
    "    y_mini = mini[:,D:]\n",
    "    return x_mini, y_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AhCrG89Es0us"
   },
   "outputs": [],
   "source": [
    "class GradientDescent:\n",
    "    \n",
    "    def __init__(self, learning_rate=.001, epsilon=1e-8, batch_size=100, iters=600, epochs=50):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iters = iters\n",
    "        self.epsilon = epsilon\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def run(self, gradient_fn, x_train, y_train, x_test, y_test, params):\n",
    "        epoch = 1\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        for epoch in range(self.epochs):\n",
    "          train_epoch_loss = []\n",
    "          test_epoch_loss = []\n",
    "          for t in range(self.iters):\n",
    "            x_mini, y_mini = create_mini_batch(x_train, y_train, self.batch_size)\n",
    "            train_loss = cost_tanh(x_mini, y_mini, params)\n",
    "            test_loss = cost_tanh(x_test, y_test, params)\n",
    "            grad = gradient_fn(x_mini, y_mini, params)\n",
    "            for p in range(len(params)):\n",
    "                params[p] -= self.learning_rate * grad[p]\n",
    "            if t % self.iters == 0:\n",
    "              print(f\"Epoch: {epoch+1}, Train error: {train_loss:.4f}, Test error: {test_loss:.4f}\")\n",
    "              epoch += 1\n",
    "            train_epoch_loss.append(train_loss)\n",
    "            test_epoch_loss.append(test_loss)\n",
    "          train_losses.append(np.mean(train_epoch_loss))\n",
    "          test_losses.append(np.mean(test_epoch_loss))\n",
    "        return params, train_losses, test_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlT4tqWfOqH1"
   },
   "source": [
    "## Task 3. Run the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJ-WzYlJ39Un"
   },
   "source": [
    "Model with 2 hidden layers and tanh activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train error: 2.3062, Test error: 2.3038\n",
      "Epoch: 2, Train error: 2.2536, Test error: 2.2479\n",
      "Epoch: 3, Train error: 2.0965, Test error: 2.0996\n",
      "Epoch: 4, Train error: 1.7271, Test error: 1.7277\n",
      "Epoch: 5, Train error: 1.2706, Test error: 1.3015\n",
      "Epoch: 6, Train error: 1.0443, Test error: 1.0389\n",
      "Epoch: 7, Train error: 0.7903, Test error: 0.8726\n",
      "Epoch: 8, Train error: 0.7730, Test error: 0.7571\n",
      "Epoch: 9, Train error: 0.7712, Test error: 0.6738\n",
      "Epoch: 10, Train error: 0.5736, Test error: 0.6098\n",
      "Epoch: 11, Train error: 0.5434, Test error: 0.5605\n",
      "Epoch: 12, Train error: 0.6325, Test error: 0.5224\n",
      "Epoch: 13, Train error: 0.4988, Test error: 0.4917\n",
      "Epoch: 14, Train error: 0.3989, Test error: 0.4672\n",
      "Epoch: 15, Train error: 0.4608, Test error: 0.4464\n",
      "Epoch: 16, Train error: 0.4310, Test error: 0.4291\n",
      "Epoch: 17, Train error: 0.3276, Test error: 0.4144\n",
      "Epoch: 18, Train error: 0.4191, Test error: 0.4014\n",
      "Epoch: 19, Train error: 0.4180, Test error: 0.3907\n",
      "Epoch: 20, Train error: 0.3590, Test error: 0.3805\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MLP2layer_tanh()\n",
    "optimizer = GradientDescent(learning_rate=2, epochs=20)\n",
    "\n",
    "model.fit(x_train, y_train, x_test, y_test, optimizer)\n",
    "\n",
    "plt.plot(np.arange(len(model.train_loss)), model.train_loss, '-', label='train')\n",
    "plt.plot(np.arange(len(model.test_loss)), model.test_loss, '-', label='test')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 90.4\n"
     ]
    }
   ],
   "source": [
    "yh = model.predict(x_test) \n",
    "accuracy = evaluate_acc(y_test, yh)\n",
    "print(f'Accuracy is {accuracy*100:.1f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "COMP551_MNP3_2lay.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
